#!/usr/bin/env python3
"""
Statistics Canada Cube File Integrity Verification System
=========================================================

Script:     06_cube_verify_files.py
Purpose:    Validate integrity of downloaded cube files and trigger re-downloads when needed
Author:     Paul Verbrugge with Claude Sonnet 4 (Anthropic)
Created:    2025
Updated:    June 2025

Overview:
--------
This critical data integrity script validates that all active cube files in the raw file 
inventory exist on disk and match their recorded SHA-256 hashes. When files are missing 
or corrupted, the script automatically cleans up the database records and triggers 
re-downloads by resetting the download_pending flag in cube_status.

Key Features:
------------
‚Ä¢ Complete file integrity verification using SHA-256 hash validation
‚Ä¢ Automatic cleanup of missing or corrupted files
‚Ä¢ Self-healing architecture that triggers re-downloads for failed files
‚Ä¢ Atomic database operations with immediate commits per file
‚Ä¢ Comprehensive logging with emoji indicators for monitoring
‚Ä¢ Fail-fast approach with individual file error isolation

Verification Process:
-------------------
1. Query all active cube files from raw_files.manage_cube_raw_files
2. For each recorded file:
   a. Check physical file existence at storage_location
   b. Calculate SHA-256 hash of file contents
   c. Compare calculated hash with recorded file_hash
   d. If file missing or hash mismatch:
      - Delete physical file (if corrupted)
      - Remove database record from manage_cube_raw_files
      - Set download_pending = TRUE in cube_status for re-download
   e. Log verification result

Database Tables Modified:
------------------------
‚Ä¢ raw_files.manage_cube_raw_files - Remove invalid file records
‚Ä¢ raw_files.cube_status - Reset download_pending flag for failed files

File Operations:
---------------
‚Ä¢ Read verification: All active cube files in /app/raw/cubes/
‚Ä¢ Delete operation: Corrupted files that fail hash validation
‚Ä¢ No file creation or modification (read-only verification)

Error Handling:
--------------
‚Ä¢ Missing files: Database cleanup and re-download trigger
‚Ä¢ Hash mismatches: File deletion, database cleanup, re-download trigger
‚Ä¢ File deletion failures: Logged but don't prevent database cleanup
‚Ä¢ Database errors: Individual file processing continues on error

Self-Healing Behavior:
---------------------
The script implements automatic recovery by:
‚Ä¢ Removing invalid database records to maintain consistency
‚Ä¢ Triggering re-downloads via download_pending flag
‚Ä¢ Deleting corrupted files to free disk space
‚Ä¢ Logging all actions for audit trail

Integration Points:
------------------
‚Ä¢ Follows: 05_cube_download.py (initial file download)
‚Ä¢ Triggers: Re-execution of 05_cube_download.py for failed files
‚Ä¢ Monitored via: /app/logs/verify_raw_files.log
‚Ä¢ Scheduled: Should run after download batches or on schedule

Performance Characteristics:
---------------------------
‚Ä¢ I/O intensive: Reads entire content of each file for hashing
‚Ä¢ Memory efficient: Processes files individually
‚Ä¢ Database efficient: Single query to get file list, individual updates
‚Ä¢ Scale: Processes all active files in single run

Usage Scenarios:
---------------
‚Ä¢ Post-download verification after batch cube downloads
‚Ä¢ Scheduled integrity checks (daily/weekly)
‚Ä¢ Diagnostic runs when data quality issues suspected
‚Ä¢ Recovery operations after disk/network issues

Usage:
------
python 06_cube_verify_files.py

Environment Requirements:
------------------------
‚Ä¢ Read access to /app/raw/cubes/ directory
‚Ä¢ Write/delete permissions for cube files
‚Ä¢ PostgreSQL connection via statcan.tools.config.DB_CONFIG
‚Ä¢ Sufficient I/O capacity for hash calculation of large files

Monitoring:
----------
‚Ä¢ Success indicator: "‚úÖ Verified {productid}: {filename}" messages
‚Ä¢ Failure indicators: "‚ùå File missing" or "‚ö†Ô∏è Hash mismatch" messages
‚Ä¢ Cleanup actions: "üóëÔ∏è Corrupted file deleted" messages
‚Ä¢ Overall status: "üéØ Verification complete" on successful run

Data Quality Assurance:
----------------------
This script is essential for maintaining data integrity in the ETL pipeline.
It ensures that downstream processing (cube ingestion, analysis) operates on
validated, uncorrupted source files. The self-healing aspect reduces manual
intervention and improves pipeline reliability.
"""

import os
import hashlib
import psycopg2
from pathlib import Path
from statcan.tools.config import DB_CONFIG
from loguru import logger

DOWNLOAD_DIR = Path("/app/raw/cubes")
logger.add("/app/logs/verify_raw_files.log", rotation="10 MB", retention="7 days")

def hash_file(file_path: Path) -> str:
    with open(file_path, "rb") as f:
        return hashlib.sha256(f.read()).hexdigest()

def verify_files():
    with psycopg2.connect(**DB_CONFIG) as conn:
        with conn.cursor() as cur:
            cur.execute("""
                SELECT productid, file_hash, storage_location
                FROM raw_files.manage_cube_raw_files
                WHERE active = TRUE
            """)
            rows = cur.fetchall()

            for productid, file_hash, file_path in rows:
                p = Path(file_path)
                if not p.exists():
                    logger.warning(f"‚ùå File missing for {productid}: {file_path}")
                    cur.execute("DELETE FROM raw_files.manage_cube_raw_files WHERE productid = %s AND file_hash = %s", (productid, file_hash))
                    cur.execute("UPDATE raw_files.cube_status SET download_pending = TRUE WHERE productid = %s", (productid,))
                    conn.commit()
                    continue

                actual_hash = hash_file(p)
                if actual_hash != file_hash:
                    logger.error(f"‚ö†Ô∏è Hash mismatch for {productid}: expected {file_hash}, got {actual_hash}")
                    try:
                        os.remove(p)
                        logger.warning(f"üóëÔ∏è Corrupted file deleted: {file_path}")
                    except Exception as e:
                        logger.exception(f"üí• Failed to delete corrupted file: {file_path}")
                    cur.execute("DELETE FROM raw_files.manage_cube_raw_files WHERE productid = %s AND file_hash = %s", (productid, file_hash))
                    cur.execute("UPDATE raw_files.cube_status SET download_pending = TRUE WHERE productid = %s", (productid,))
                    conn.commit()
                else:
                    logger.info(f"‚úÖ Verified {productid}: {p.name}")

def main():
    logger.info("üîç Starting raw file verification...")
    try:
        verify_files()
        logger.success("üéØ Verification complete.")
    except Exception as e:
        logger.exception(f"üí• Verification failed: {e}")

if __name__ == "__main__":
    main()

